package org.fogbeam.example.opennlp.training;

import java.io.*;
import opennlp.tools.tokenize.*;

public class TokenizerApp {
    public static void main(String[] args) {
        try {
            // Ruta al modelo de tokenización
            TokenizerModel model = new TokenizerModel(new FileInputStream("models/en-token.model"));
            TokenizerME tokenizer = new TokenizerME(model);

            // Directorio de entrada donde están los archivos de texto
            File inputFolder = new File("demo_data");
            File[] files = inputFolder.listFiles((dir, name) -> name.endsWith(".txt"));

            // Archivo de salida para guardar los tokens
            try (BufferedWriter writer = new BufferedWriter(new FileWriter("output/tokens.txt"))) {
                for (File file : files) {
                    System.out.println("Procesando archivo: " + file.getName());
                    try (BufferedReader reader = new BufferedReader(new FileReader(file))) {
                        String line;
                        while ((line = reader.readLine()) != null) {
                            // Tokeniza la línea actual
                            String[] tokens = tokenizer.tokenize(line);
                            // Escribe los tokens en el archivo de salida
                            for (String token : tokens) {
                                writer.write(token + " ");
                            }
                            writer.newLine();
                        }
                    }
                }
            }

            System.out.println("Tokenización completada. Resultados en 'output/tokens.txt'");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
